{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Category</th>\n",
       "      <th>Retweet</th>\n",
       "      <th>Processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i love lebron. http://bit.ly/PdHur</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NN love NN _link_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ludajuice Lebron is a Beast, but I'm still ch...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>_at_someone_ NN is a NN but NN RB cheer CD the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@wordwhizkid Lebron is a beast... nobody in th...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>_at_someone_ NN is a NN NN in the NN come RB JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bill Simmons in conversation with Malcolm Glad...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NN NNS in NN with NN NN _link_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>playing with Java and the Twitter API</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>play with NN and the NN NN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Category  Retweet  \\\n",
       "0                 i love lebron. http://bit.ly/PdHur         0    False   \n",
       "1  @ludajuice Lebron is a Beast, but I'm still ch...         0    False   \n",
       "2  @wordwhizkid Lebron is a beast... nobody in th...         0    False   \n",
       "3  Bill Simmons in conversation with Malcolm Glad...         0    False   \n",
       "4              playing with Java and the Twitter API         0    False   \n",
       "\n",
       "                                           Processed  \n",
       "0                                  NN love NN _link_  \n",
       "1  _at_someone_ NN is a NN but NN RB cheer CD the...  \n",
       "2    _at_someone_ NN is a NN NN in the NN come RB JJ  \n",
       "3                     NN NNS in NN with NN NN _link_  \n",
       "4                         play with NN and the NN NN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pickle.load( open( \"files/df.pickle\", \"rb\" ) )\n",
    "df = df[df['Retweet']==False]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1730344,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Russian Words\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X1, Xh1, y1, yh1 = train_test_split(df[df['Category']==1]['Processed'], df[df['Category']==1]['Category'], train_size=0.75)\n",
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1730343,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Non-Russian Words\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X0, Xh0, y0, yh0 = train_test_split(df[df['Category']==0]['Processed'], df[df['Category']==0]['Category'], train_size=(X1.shape[0]/df[df['Category']==0].shape[0]))\n",
    "X0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3460687,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.concatenate((X0,X1), axis=0)\n",
    "y = np.concatenate((y0,y1), axis=0)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3460687 Number of tweets has 16145 cols and took 338 s\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# run a countvectorizer on the Tweets\n",
    "start = time.time()\n",
    "countVectorizer =  TfidfVectorizer(ngram_range=(2,5)\n",
    "                                    , min_df = 500\n",
    "                                    , max_df = .7\n",
    "                                    , stop_words = None\n",
    "                                   )\n",
    "countVectorizer.fit(X)\n",
    "\n",
    "\n",
    "\n",
    "countVectorizer.stop_words_ = None\n",
    "pickle.dump( countVectorizer, open( \"models/countVectorizer.pickle\", \"wb\" ) )\n",
    "\n",
    "end = time.time()\n",
    "print('{} Number of tweets has {} cols and took {:.0f} s'.format(X.shape[0], countVectorizer.transform(X1).shape[1],end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3460687 Number of tweets has 16145 cols and took 176 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "start = time.time()\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X = countVectorizer.transform(X)\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "pickle.dump( scaler, open( \"models/scaler.pickle\", \"wb\" ) )\n",
    "end = time.time()\n",
    "print('{} Number of tweets has {} cols and took {:.0f} s'.format(X.shape[0], X.shape[1],end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8964128506288732 0.8932027388773561 Took 1356.841005563736 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "start = time.time()\n",
    "model = LogisticRegression(max_iter=10, penalty='l1', solver='saga')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "model.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print(model.score(X_train, y_train), model.score(X_test, y_test),\"Took {} s\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9093540982390492"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(scaler.transform(countVectorizer.transform(np.concatenate((Xh0, Xh1), axis=0))), np.concatenate((yh0,yh1),axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( model, open( \"models/regression.pickle\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = pickle.load( open( \"models/countVectorizer.pickle\", \"rb\" ) )\n",
    "scaler = pickle.load( open( \"models/scaler.pickle\", \"rb\" ) )\n",
    "lr = pickle.load( open( \"models/regression.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = lr.predict_proba(scaler.transform(cv.transform(np.concatenate((Xh0,Xh1), axis=0))))\n",
    "\n",
    "y_test = np.concatenate((yh0,yh1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score[:,1])\n",
    "roc_auc = auc(fpr,tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr,tpr,color='b',label='ROC Curve {:.3f}'.format(roc_auc))\n",
    "plt.plot([0,1],[0,1],color='k',linestyle='--')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim(0,1.01)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Reciever-Operator Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "threshold = [0.1*a for a in range(101)]\n",
    "for th in threshold:\n",
    "    scores.append(np.sum((y_score[:,1]>=th)==y_test)/y_test.shape[0])\n",
    "plt.figure()\n",
    "plt.plot(threshold,scores, label='Best Score {:.3f} at {:.2f}'.format(np.max(scores), threshold[scores.index(np.max(scores))]))\n",
    "plt.hlines(0.5,0,1,color='k',linestyle='--')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim(0,1.01)\n",
    "plt.xlabel('Threshold of Predict_Proba[Russian]')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Threshold Exploration')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
